# XAI-LIME-SHAP-CF-Streamlit
We have used explainable AI methods (Lime, Shap and counterfactual) on a Churn Classification dataset and identified the most important features contributing to the model's prediction and how changing those features would affect the prediction outcome and deployed the our model on streamlit.

# Steps Taken:

**Normalization**
We Split the dataset into training and testing sets. Used appropriate preprocessing
techniques, such as normalization or feature selection, to ensure high-quality input for
your models. We used Standard Scaling.

**Train Test Split**
We Trained and compareed the performance of three corresponding Machine Learning algorithms.
Then Choosed the best algorithm based on the evaluation metrics (e.g., accuracy, ROC AUC, RMSE, etc.) on the
test set.

**Model Selection**
Selected the best model, and used **LIME, Shapley, and Counterfactual** to explain how the
model makes decisions on three sample scenarios (instances from the test set).
Specifically, identify the most important features contributing to the model's prediction
and how changing those features would affect the prediction outcome.

**Deployment**
We Implemented a programming interface using either Streamlit that allows users to
interact with your ensemble model and get explanations for the predictions made. Our
interface should allow users to input the feature values for a new instance and display
the corresponding prediction and explanations generated by LIME, Shapley, and
Counterfactual.
